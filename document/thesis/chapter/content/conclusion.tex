\chapter{Conclusion and Future work}
During this thesis, we have proposed a promising system to recognize hand gestures based on skeletal points tracking using depth camera. This system is built for the purpose of human-robot interaction (HRI) with the humanoid robot named as NAO. We have validated this approach by training the system with five static gestures and we have obtained good results. 

We have partitioned our goal into 4 modules and reached the goal by implementing them in a decoupled environment, and finally, integrated all of them into one system. We believe that the proposed approach is sufficiently robust and flexible to deal with static and temporal hand gestures. 

Human-Robot Interaction module deals with integrating the depth camera into the robot and processing the depth information to track skeletal points of the user, and finally send them via network to Brain module. Brain module supports the core functionalities of this system by receiving the skeletal point information of the user, and recording them as training data in the training mode or computing the prediction results in the prediction mode. Control Center module plays vital role in visualizing these interactions, therefore, it is considered as the eye of the system. Finally, Command module comprehends the predicted gesture and translating them to a robotic Motion or Speech or Gesture itself.

Finally, we have carried out several experiments and provided the results illustrates the robustness of the system. Furthermore, we have done evaluations on the test data and plotted them on graph to visually understand the performance of the system. Moreover, we have proposed alternatives to improve the efficiency and the effectiveness of our system. For instance, the gesture recognizing performance can be then improved incrementally by learning from on-line training feature of Adaptive Naive Bayes classifier. Additionally, evaluation results show that Minimum Distance classifier could be a better alternative.
 
\section{Future Work}
The proposed design for gesture recognition based on skeletal points tracking using depth camera can be improved in several ways. In this section, we overview the future work by discussing the limitations of the proposed methods and proposing the alternatives.

\begin{itemize}
		\item \textbf{Networking} : 4 modules of this system is connected via several networking components such as UDP Server-Client, Websocket Server-Client and NAOqi proxy. Server-Client networking topology involving different communication protocol is a big limitation, since every module have implemented their own server or client functionalities of UDP or WebSocket. Furthermore, data is serialized as JSON strings and must be parsed at the receiver side to extract the data. Hence, we propose Open Sound Control (OSC) protocol that covers all these requirements in one framework with distributed networking topology.
		
		\item \textbf{Graphical User Interface} : Since the components of this system are modularized and developed independently, the development environment varies with each other. Even though WebGL is easier and flexible graphics library, it takes a lot of processing power as it runs on the browser. Instead of using several programming languages, the system could be implemented with C++ GUI using QT or Microsoft Visual C++ and OpenGL. We propose to integrate the existing code into such framework to build this system as standalone application. 
		
		\item \textbf{Skeleton Joints} :  Due to computational limitations of NAO, in this thesis, we have used only hand joints of the user to train and classify the gestures. Classification based on positions of only hand joints does not allow us to train many gestures because the gesture model will higher rate of confusion. For instance, in Cartesian coordinates "Hands Up" gesture trained at different distances from the sensor will be confused with "Hands Wide". Therefore, we propose to make use of other skeleton joints such as shoulder and arm to calculate the orientation of hand in polar coordinates.
		
		\item \textbf{Computational Limitations of NAO} : In this thesis, HRI module is deployed to general purpose computer of NAO. HRI module is responsible for tracking the hand or full skeleton joints with the help of NiTE framework. NiTE uses computationally intensive algorithms and causes higher CPU utilization of NAO. Therefore, we propose to transmit the depth information from OpenNI device completely to NiTE application on an off-board computer. This could be achieved by using Robot Operating System (ROS) framework that already has a solution to transmit depth information via network.
		
\end{itemize}