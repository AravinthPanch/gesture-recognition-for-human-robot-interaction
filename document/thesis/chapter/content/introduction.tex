\chapter{Introduction}
Huge influence of computers in society has made smart devices, an important part of our lives. Availability and affordability of such devices motivated us to use them in our day-to-day living. The list of smart devices includes personal automatic and semi-automatic robots which are also playing a major role in our household. For an instance, Roomba \cite{8} is an autonomous robotic vacuum cleaners that automatically cleans the floor and goes to its charging station without human interaction.

Interaction with smart devices has still been mostly through displays, keyboards, mouse and touch interfaces. These devices have grown to be familiar but inherently limit the speed and naturalness with which we can interact with the computer.  Usage of robots for domestic and industrial purposes has been continuously increasing. Thus in recent years, there has been a tremendous push in research toward an intuitive and easy communication with the robot through speech, gestures and facial expressions.

Tremendous progress had been made in speech recognition and several commercially successful speech interfaces are available. However, speech recognition systems have certain limitations such as misinterpretation due to various accents and background noise interference. It may not be able to differentiate between your speech, other people talking and other ambient noise, leading to transcription mix-ups and errors.

Furthermore, there has been an increased interest in recent years in trying to introduce other human-to-human communication modalities into HRI. This includes a class of techniques based on the movement of the human arm and hand, or hand gestures. The use of hand gestures provides an attractive alternative for Human-robot interaction than the conventional cumbersome devices.

\paragraph*{Goal} In this thesis, we aim at developing a hand gesture recognition system based on skeletal points tracking using depth camera. This system should be capable of recognizing hand gestures in real time and it should be consistent among different users. Furthermore, this system must be integrated into the humanoid robot NAO, thus, the recognized gestures must be comprehended by NAO to execute a certain predefined task. In this manner, Human-Robot Interactions are incorporating human-to-human communication modalities, hence, providing a natural interaction between human and the robot.

\paragraph*{Background} To begin with, we have studied key concepts, state of the art solutions and tools available to accomplish the goal. Chapter \ref{ch:background} thoroughly discusses about the humanoid robot and stages of gesture recognition with the help of computer vision and machine learning algorithms. In details, this chapter explains the concepts of gesture modeling, feature extraction from depth data by NiTE framework, learning and classification of hand gestures using Adaptive Naive Bayes Classifier with the help of Gesture Recognition Toolkit (GRT).

\paragraph*{Solution} In addition to that, Chapter \ref{ch:solution} talks about the functional blocks of system and how they are implemented to provide an efficient solution. Furthermore, it illustrates the functionalities of  Human-Robot Interaction (HRI) module, Brain module, Control Center module and Command module, and how they all are integrated into a robust system.

\paragraph*{Results and Evaluation} Finally, Chapter \ref{ch:result} and \ref{ch:evaluation} show promising results in recognizing five static hand gestures which are trained in supervised lab condition. It shows not only the performances of gesture prediction, but also the human-robot interactions where the robot has executed a predefined tasks when the hand gestures are recognized. Evaluation demonstrates the effectiveness of the system and to evaluate its potential for real time application. Finally, experiment parameters are presented and compared with other available solutions.

\paragraph*{Conclusion} In a conclusion, this manuscript demonstrate how the goal to build a hand gesture recognition based on skeletal points tracking using depth camera is accomplished, as well as, how this system can be improved in several ways by proposing various alternatives.