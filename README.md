Gesture Recognition For Human-Robot Interaction
===============================================

Abstract
--------------------------------------
<p align="justify">
Human-robot interaction (HRI) has been a topic of both science fiction and academic speculation even before any robots
existed. HRI research is focusing to build an intuitive and easy communication with the robot through speech, gestures,
and facial expressions. The use of hand gestures provides an attractive alternative to complex interfaced devices for HRI.
In particular, visual interpretation of hand gestures can help in achieving the ease and naturalness desired for HRI.
This has motivated a very active research concerned with computer vision-based analysis and interpretation of hand gestures.
Important differences in the gesture interpretation approaches arise depending on whether 3D based model or appearance
based model of the gesture is used.
</p>

<p align="justify">
In this thesis, we attempt to implement the hand gesture recognition for robots with modeling, training, analyzing and
recognizing gestures based on computer vision and machine learning techniques. Additionally, 3D based gesture modeling
with skeletal points tracking will be used. As a result, on the one side, gestures will be used command the robot to
execute certain actions and on the other side, gestures will be translated and spoken out by the robot.
</p>

<p align="justify">
We further hope to provide a platform to integrate Sign Language Translation to assist people with hearing and speech
disabilities. However, further implementations and training data are needed to use this platform as a full fledged
Sign Language Translator.
</p>

![Architecture](./document/diagram/hri-architecture.png "Architecture")


Motivation
--------------------------------------

<p align="justify">
Huge influence of computers in society has made smart devices, an important part of our lives. Availability and
affordability of such devices motivated us to use them in our day-to-day living. The list of smart devices includes
personal automatic and semi-automatic robots which are also playing a major role in our household. For an instance,
Roomba is an autonomous robotic vacuum cleaners that automatically cleans the floor and goes to its charging station
without human interaction.
</p>

<p align="justify">
Interaction with smart devices has still been mostly through displays, keyboards, mouse and touch interfaces.
These devices have grown to be familiar but inherently limit the speed and naturalness with which we can interact with
the computer.  Usage of robots for domestic and industrial purposes has been continuously increasing.
Thus in recent years, there has been a tremendous push in research toward an intuitive and easy communication with the
robot through speech, gestures and facial expressions.
</p>

<p align="justify">
Tremendous progress had been made in speech recognition and several commercially successful speech interfaces are
available. However, speech recognition systems have certain limitations such as misinterpretation due to various accents
and background noise interference. It may not be able to differentiate between your speech, other people talking and
other ambient noise, leading to transcription mix-ups and errors.
</p>

<p align="justify">
Furthermore, there has been an increased interest in recent years in trying to introduce other human-to-human
communication modalities into HRI. This includes a class of techniques based on the movement of the human arm and hand,
or hand gestures. The use of hand gestures provides an attractive alternative for Human-robot interaction than
the conventional cumbersome devices.
</p>